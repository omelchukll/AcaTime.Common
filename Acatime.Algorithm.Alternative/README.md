# Алгоритм складання розкладу AcaTime.Algorithm.Genetic

## Опис алгоритму

Алгоритм `DefaultScheduleAlgorithmUnit` реалізує модифікований метод "пошуку з поверненням" (backtracking search) для розв'язання задачі складання навчального розкладу, що належить до класу NP-складних задач задоволення обмежень (Constraint Satisfaction Problem, CSP). Даний метод інтегрує ряд евристичних оптимізацій та стохастичних елементів:

- **MRV** (Minimum Remaining Values) – евристика вибору змінної з найменшою кількістю валідних значень, що значно зменшує фактор розгалуження дерева пошуку
- **LCV** (Least Constraining Value) – евристика сортування доменних значень за мірою їх впливу на обмеження інших змінних
- **Forward Checking** – превентивний механізм видалення несумісних значень з доменів суміжних змінних після кожного призначення
- **Стохастичний пошук** – елемент випадковості у виборі змінних та значень для диверсифікації пошуку і уникнення локальних оптимумів

## Математична модель

### Змінні задачі CSP
- Множина змінних X = {x₁, x₂, ..., xₙ}, де кожна xᵢ представляє навчальне заняття
- Кожна змінна xᵢ описується атрибутами: предмет, група студентів, викладач, тип заняття

### Домени змінних
- Для кожної змінної xᵢ визначено домен Dᵢ = {dᵢ₁, dᵢ₂, ..., dᵢₘ}
- Кожне значення домену dᵢⱼ представляє комбінацію "дата-час-аудиторія"

### Обмеження
Множина обмежень C = {C₁, C₂, ..., Cₖ}, де обмеження поділяються на категорії:
- **Жорсткі обмеження** (hard constraints) – умови, що обов'язково повинні виконуватися:
  - Один викладач не може проводити два заняття одночасно
  - Група студентів не може бути присутня на двох заняттях одночасно
  - Аудиторія не може використовуватися для двох занять одночасно
  - Аудиторія повинна відповідати типу заняття та вміщувати необхідну кількість студентів

- **М'які обмеження** (soft constraints) – бажані, але не обов'язкові умови:
  - Мінімізація "вікон" у розкладі студентів та викладачів
  - Рівномірний розподіл занять протягом тижня
  - Врахування переваг викладачів щодо часу проведення занять

## Ключові компоненти алгоритму

### Структура даних
- `FacultySeasonDTO` - інкапсуляція даних факультету, семестру, предметів, груп, викладачів та аудиторій
- `SlotTracker` - структура відстеження стану змінної, містить поточні та відкинуті доменні значення
- `DomainValue` - атомарне значення домену, що включає дату та часовий інтервал

### Формалізація рекурсивного пошуку

1. **Ініціалізація**
   - Формування початкового стану S₀, де всі змінні не призначені
   - Встановлення поточної глибини рекурсії d = 1

2. **Рекурсивна функція AssignSlots(d)**
   - Вибір наступної незаповненої змінної xᵢ за евристикою MRV
   - Якщо всі змінні призначені, повернути поточний стан Sₖ як розв'язок
   - Впорядкування домену Dᵢ за допомогою евристики LCV
   - Ітерація по впорядкованому домену Dᵢ:
     - Для кожного значення dᵢⱼ ∈ Dᵢ:
       - Якщо dᵢⱼ відповідає всім обмеженням C при поточному стані Sₖ:
         - Створити новий стан Sₖ₊₁ = Sₖ ∪ {xᵢ = dᵢⱼ}
         - Застосувати Forward Checking для оновлення доменів пов'язаних змінних
         - Рекурсивно викликати AssignSlots(d+1)
         - Якщо рекурсивний виклик успішний, повернути результат
         - Інакше відновити стан Sₖ (backtracking)
   - Якщо жодне значення не підходить, повернути failure

## Стохастичний аспект пошуку

Алгоритм інтегрує елементи стохастичного пошуку через модифіковану функцію вибору:

1. **Температурна модель вибору**  
   При виборі змінної xᵢ та значення dᵢⱼ використовується функція розподілу ймовірностей, що є варіантом функції SOFTMAX:
   
   P(xᵢ) = exp(f(xᵢ)/T) / ∑ₖ exp(f(xₖ)/T)
   
   де:
   - f(xᵢ) - оціночна функція для змінної або значення
   - T - параметр "температури", що регулює ступінь випадковості

2. **Адаптивне дослідження простору розв'язків**
   - Параметр SlotsTemperature контролює ймовірність вибору не оптимальної за MRV змінної
   - Параметр DomainsTemperature регулює ймовірність вибору не оптимального за LCV значення
   - За T → 0, вибір наближається до детермінованого (жадібного)
   - За T → ∞, вибір наближається до рівномірно-випадкового

Такий підхід дозволяє ефективно балансувати між:
- Exploitation (використання найкращих відомих варіантів)
- Exploration (дослідження потенційно перспективних областей)

## Паралельна імплементація

Алгоритм адаптовано для паралельного виконання за моделлю "розділяй і володарюй":

1. **Незалежні траєкторії пошуку**
   - Запуск N незалежних екземплярів алгоритму з однаковими параметрами
   - Завдяки стохастичності, кожний екземпляр може досліджувати різні частини простору розв'язків, що призводить до різних рішень
   - Формальне представлення як N-арного паралельного пошуку в просторі станів

2. **Математична модель масштабування**
   - Теоретичне прискорення: S(N) ≤ N, де N - кількість паралельних екземплярів
   - Фактичне прискорення залежить від розподілу складності підзадач
   - Імовірність знаходження розв'язку: P(N) = 1 - (1-p)ᴺ, де p - імовірність знаходження розв'язку одним екземпляром

## Перевірка наявності аудиторій

Алгоритм включає механізм перевірки та призначення аудиторій для занять:

1. **Жадібний підхід**
   - Для кожного слоту перевіряється наявність доступних аудиторій, що відповідають вимогам за типом та розміром
   - Аудиторії сортуються за пріоритетом та обирається найкраща доступна
   - Активно використовує кешування, що дозволяє швидше знаходити рішення порівняно з алгоритмом Хопкрофта-Карпа

2. **Алгоритм Хопкрофта-Карпа**
   - Якщо жадібний підхід не знаходить рішення, застосовується алгоритм Хопкрофта-Карпа для оптимального перерозподілу аудиторій
   - Це дозволяє знайти оптимальний розподіл аудиторій для всіх слотів, включаючи поточний

## Параметризація алгоритму

Алгоритм конфігурується через набір параметрів, що впливають на ефективність пошуку:

| Параметр | Формальний опис | Вплив на характеристики пошуку |
|----------|------|-------|
| `SlotsTopK` | Розмір множини змінних-кандидатів для стохастичного вибору | Збільшення призводить до розширення траверсованого простору станів при потенційному зростанні обчислювальної складності |
| `SlotsTemperature` | Коефіцієнт T у функції розподілу ймовірностей для вибору змінної | Регулює баланс між детермінованим (T→0) та випадковим (T→∞) вибором |
| `DomainsTopK` | Розмір підмножини доменних значень для стохастичного вибору | Визначає ступінь локального дослідження простору значень окремої змінної |
| `DomainsTemperature` | Коефіцієнт T у функції розподілу ймовірностей для вибору значення | Аналогічно SlotsTemperature, але на рівні окремих доменних значень |
| `IgnoreClassrooms` | Булева змінна для деактивації обмежень щодо аудиторій | Спрощує задачу CSP шляхом зменшення кількості обмежень |
| `UserFunctions` | Множина користувацьких предикатів для валідації та оцінювання | Дозволяє інтегрувати додаткові евристики та обмеження |

## Використання алгоритму

```csharp
// Формування параметрів алгоритму
var parameters = new AlgorithmParams
{
    SlotsTopK = 5,
    SlotsTemperature = 0.7,
    DomainsTopK = 10,
    DomainsTemperature = 0.5
};

// Ініціалізація алгоритму
var algorithm = new DefaultScheduleAlgorithmUnit();
algorithm.Setup(facultySeasonData, logger, userFunctions, parameters);

// Однопотокове виконання
var result = await algorithm.Run(cancellationToken, ignoreClassrooms);

// Багатопотокове виконання
var tasks = new List<Task<AlgorithmResultDTO>>();
for (int i = 0; i < 4; i++)
{
    var parallelAlgorithm = new DefaultScheduleAlgorithmUnit();
    parallelAlgorithm.Setup(facultySeasonData, logger, userFunctions, parameters);
    tasks.Add(parallelAlgorithm.Run(cancellationToken, ignoreClassrooms));
}

// Агрегація результатів
var results = await Task.WhenAll(tasks);
var bestResult = results.Where(r => r != null).OrderByDescending(r => r.TotalEstimation).FirstOrDefault();
``` 